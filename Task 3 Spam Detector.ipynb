{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4477698",
   "metadata": {},
   "source": [
    "## importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc5c4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import chardet\n",
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d273e",
   "metadata": {},
   "source": [
    "## Getting a text dataset\n",
    "the dataset we are going to be using is kaggle spam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbaf0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spam.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "\n",
    "df = pd.read_csv('spam.csv', encoding=result['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3473b004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d45255",
   "metadata": {},
   "source": [
    "## Preprocessing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7258c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming dataset columns\n",
    "df.rename(columns={'v2': 'text', \"v1\": 'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e6aee1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# deleting unwanted columns\n",
    "del df[\"Unnamed: 2\"]\n",
    "del df[\"Unnamed: 3\"]\n",
    "del df[\"Unnamed: 4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "761bfdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham              Will Ì_ b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15eb3785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting target column to one hot encoded\n",
    "df = pd.get_dummies (df, columns = [\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60bce537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_ham</th>\n",
       "      <th>target_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target_ham  target_spam\n",
       "0  Go until jurong point, crazy.. Available only ...           1            0\n",
       "1                      Ok lar... Joking wif u oni...           1            0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...           0            1\n",
       "3  U dun say so early hor... U c already then say...           1            0\n",
       "4  Nah I don't think he goes to usf, he lives aro...           1            0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571ac54",
   "metadata": {},
   "source": [
    "#### spam = 0 and Ham = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73b404d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Go until jurong point, crazy.. Available only ...       1\n",
       "1                      Ok lar... Joking wif u oni...       1\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...       0\n",
       "3  U dun say so early hor... U c already then say...       1\n",
       "4  Nah I don't think he goes to usf, he lives aro...       1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df[\"target_spam\"]\n",
    "df.rename(columns={\"target_ham\": \"target\"}, inplace=True)\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a130a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (Ham)\n",
      "Text:\n",
      "Dunno leh cant remember mayb lor. So wat time r we meeting tmr?\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1 (Ham)\n",
      "Text:\n",
      "Best msg: It's hard to be with a person, when u know that one more step foward will make u fall in love.. &amp; One step back can ruin ur friendship.. good night:-) ...\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0 (Spam)\n",
      "Text:\n",
      "URGENT! Your Mobile number has been awarded with a å£2000 prize GUARANTEED. Call 09061790126 from land line. Claim 3030. Valid 12hrs only 150ppm\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1 (Ham)\n",
      "Text:\n",
      "Helloooo... Wake up..! \\Sweet\\\" \\\"morning\\\" \\\"welcomes\\\" \\\"You\\\" \\\"Enjoy\\\" \\\"This Day\\\" \\\"with full of joy\\\".. \\\"GUD MRNG\\\".\"\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1 (Ham)\n",
      "Text:\n",
      "Vikky, come around  &lt;TIME&gt; ..\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualise some random training examples\n",
    "random_index = random.randint (0, len (df) - 5)\n",
    "for row in df[[\"text\", \"target\"]][random_index: random_index + 5].itertuples ():\n",
    "    _, text, target = row\n",
    "    print (f\"Target: {target}\", \"(Ham)\" if target > 0 else \"(Spam)\")\n",
    "    print (f\"Text:\\n{text}\\n\")\n",
    "    print (\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa9288da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4825\n",
       "0     747\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the num of classes in our target variable\n",
    "df.target.value_counts ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef65b73",
   "metadata": {},
   "source": [
    "## Data balancing\n",
    "it's quiet obvious that our dataset category is imbalanced so let's balance it\n",
    "\n",
    "#### Resampling Techniques:\n",
    "\n",
    "- **Over-sampling**: Increase the number of instances in the minority class by randomly duplicating them or generating synthetic examples. Popular techniques include SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "- **Under-sampling**: Reduce the number of instances in the majority class by randomly removing examples. Be cautious with under-sampling as it may lead to loss of valuable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "004bf829",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "1    3860\n",
      "0     597\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"No I'm in the same boat. Still here at my moms. Check me out on yo. I'm half naked.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26896\\2921291890.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Apply SMOTE to the training set with a specific sampling strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0msmote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mx_train_sampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Display the class distribution after applying SMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    870\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    871\u001b[0m         \"\"\"\n\u001b[1;32m--> 872\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: \"No I'm in the same boat. Still here at my moms. Check me out on yo. I'm half naked.\""
     ]
    }
   ],
   "source": [
    "# defining our depedent and independent variables\n",
    "x = df[\"text\"]\n",
    "y = df[\"target\"]\n",
    "\n",
    "# splitting dataset into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split (x, y, train_size = 0.8, random_state = 42)\n",
    "\n",
    "# Display the class distribution before applying SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Apply SMOTE to the training set with a specific sampling strategy\n",
    "smote = SMOTE(sampling_strategy=0.7, random_state=42)\n",
    "x_train_sampled, y_train_sampled = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# Display the class distribution after applying SMOTE\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120892d",
   "metadata": {},
   "source": [
    "## Splitting our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef472e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our depedent and independent variables\n",
    "x = df[\"text\"]\n",
    "y = df[\"target\"]\n",
    "\n",
    "# splitting dataset into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split (x.to_numpy (), y.to_numpy (), train_size = 0.8, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd449d7c",
   "metadata": {},
   "source": [
    "## text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97c7716b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number tokens in the training tweets\n",
    "round (sum ([len (i.split ()) for i in x_train]) / len (x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "281f8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing our text dataset\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "## setup text vectorization variables\n",
    "max_vocab_length = 1000\n",
    "max_length = 15  # how long our sequence will be\n",
    "\n",
    "text_vectorizer = TextVectorization (max_tokens = max_vocab_length,\n",
    "                                     output_mode = \"int\",\n",
    "                                     output_sequence_length = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f99a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the traininig text\n",
    "text_vectorizer.adapt (x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "94b608c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 1,  1, 15,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"osas ceo of coding pivots?\"\n",
    "text_vectorizer ([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d5c6b87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " Haha... Really oh no... How? Then will they deduct your lesson tmr? \n",
      "\n",
      "Tokenize version:\n",
      " tf.Tensor([[239 162 129  40  54  64  35 110   1  14 581 417   0   0   0]], shape=(1, 15), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice (x_train)\n",
    "print (\"Original text:\\n\", random_sentence, \"\\n\\nTokenize version:\\n\",  text_vectorizer ([random_sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e9f2f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 1000\n",
      "5 most common words: ['', '[UNK]', 'to', 'i', 'you']\n",
      "5 least common words: ['paying', 'nyt', 'noon', 'none', 'nigeria']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary ()  # get all the unique words in our vocabulary\n",
    "top_5_words = words_in_vocab[:5]  # get the most common words\n",
    "bottom_5_words = words_in_vocab[-5:]  # get the least common words\n",
    "print (f\"Number of words in vocab: {len (words_in_vocab)}\")\n",
    "print (f\"5 most common words: {top_5_words}\")\n",
    "print (f\"5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127fe58",
   "metadata": {},
   "source": [
    "## Create an embedding using Tensorflow embedding layer\n",
    "Embeddings transform positive integers into compact vectors of a consistent size. The crucial parameters for our embedding layer are as follows:\n",
    "- `input_dim`: the size of our vocabulary\n",
    "- `output_dim`: the dimensionality of the resulting embedding vector; for instance, a setting of 200 implies that each token is encoded as a vector with 200 dimensions\n",
    "- `input_length`: the length of the sequences supplied to the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "abe1720f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.embeddings.Embedding at 0x18f30009e50>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding (input_dim = max_vocab_length, \n",
    "                              output_dim = 128,\n",
    "                             input_length = max_length)\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e71d301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: \n",
      " URGENT, IMPORTANT INFORMATION FOR O2 USER. TODAY IS YOUR LUCKY DAY! 2 FIND OUT WHY LOG ONTO HTTP://WWW.URAWINNER.COM THERE IS A FANTASTIC SURPRISE AWAITING FOR YOU \n",
      "\n",
      "Tokenized version: \n",
      " [[190 464 784  13   1 883  95  10  14 579  69  22 175  55 169]]\n",
      "\n",
      "Embedded Version: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.00430927,  0.03193492, -0.03968967, ..., -0.03643664,\n",
       "         -0.01620886,  0.01653708],\n",
       "        [ 0.0017296 , -0.01883905,  0.0421573 , ...,  0.0250286 ,\n",
       "          0.04810629,  0.0300197 ],\n",
       "        [-0.02490152, -0.032251  ,  0.02536373, ...,  0.01567742,\n",
       "          0.03691034,  0.00890841],\n",
       "        ...,\n",
       "        [ 0.0042261 ,  0.04831162, -0.00775467, ..., -0.02069246,\n",
       "          0.0471291 ,  0.01411555],\n",
       "        [-0.01191616,  0.04681437, -0.03649992, ..., -0.01919986,\n",
       "          0.00486423,  0.04056931],\n",
       "        [ 0.00250328, -0.01777841, -0.01844982, ...,  0.01759103,\n",
       "          0.03286393, -0.01302002]]], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## So let's test our embedding tf layer with a random sample\n",
    "random_sentence = random.choice (x_train)\n",
    "print (f\"Original text: \\n {random_sentence} \\n\\nTokenized version: \\n {text_vectorizer ([random_sentence])}\\n\\nEmbedded Version: \")\n",
    "sample_embed = embedding (text_vectorizer ([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8c41eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single token embed: \n",
      "[-4.30927426e-03  3.19349207e-02 -3.96896712e-02  4.20137309e-02\n",
      "  2.76331417e-02  3.23105194e-02 -6.42098114e-03 -4.14739363e-02\n",
      "  1.85583904e-03 -4.02107127e-02  7.52482563e-03  2.65669934e-02\n",
      " -2.35676765e-04 -3.03605329e-02  3.92581150e-03  4.59532477e-02\n",
      " -6.86192513e-03 -1.89391524e-03  8.42101872e-05 -4.60703969e-02\n",
      "  4.88206185e-02 -9.17595625e-03 -2.59319898e-02  4.26017381e-02\n",
      " -2.72915605e-02 -3.43948007e-02  2.13908032e-03 -2.48587616e-02\n",
      " -3.87796760e-02 -2.57640015e-02  3.11478637e-02 -1.90796740e-02\n",
      "  8.94080475e-03 -4.83648665e-02  4.47187312e-02 -9.71783325e-03\n",
      " -1.48541816e-02 -2.52982378e-02 -2.42007133e-02 -1.93093307e-02\n",
      "  2.27768458e-02  4.90573905e-02  8.89512151e-03 -4.28089760e-02\n",
      "  4.35368754e-02  4.15120758e-02  4.07089032e-02  1.98472850e-02\n",
      "  2.96027921e-02 -1.10615976e-02 -4.53276411e-02 -3.60886827e-02\n",
      " -1.27412789e-02  1.67534389e-02  1.80754177e-02  4.80070971e-02\n",
      "  4.53468412e-03 -3.00048236e-02 -2.29531880e-02 -3.74512300e-02\n",
      "  1.52924396e-02  2.93538459e-02  2.10447796e-02  8.93140957e-03\n",
      " -7.75256008e-03 -2.52926350e-02  4.51557525e-02  3.47929113e-02\n",
      "  2.10887194e-03 -4.56382893e-02  6.42737001e-03 -2.73650531e-02\n",
      "  4.39606607e-04  2.48442180e-02  2.27229670e-03 -4.77082729e-02\n",
      "  2.30169334e-02  4.58931588e-02  9.17079300e-03 -3.45380902e-02\n",
      "  3.90981510e-03  3.53028513e-02 -4.13999334e-02 -1.82983875e-02\n",
      " -4.18727398e-02  3.76687199e-03 -4.34632674e-02 -2.88445242e-02\n",
      "  4.97064479e-02 -1.22382417e-02 -3.85003164e-03  2.02800073e-02\n",
      "  2.14489959e-02 -3.87880914e-02  2.77346037e-02 -3.30987796e-02\n",
      "  1.71163715e-02 -3.48465666e-02 -1.75194517e-02 -3.77251618e-02\n",
      " -3.63723151e-02  2.39385478e-02 -2.52490286e-02  1.14395395e-02\n",
      "  2.24478506e-02  1.27780773e-02  1.14402883e-02 -2.87345406e-02\n",
      "  4.91713360e-03  4.22464646e-02 -2.54671648e-03  4.07990254e-02\n",
      " -2.67509222e-02  3.63872163e-02  6.08336180e-04  3.48477438e-03\n",
      " -9.91190597e-03  3.88514139e-02 -2.80128848e-02  3.82830985e-02\n",
      " -2.98109651e-02  3.03804167e-02  3.94892134e-02  1.23091340e-02\n",
      " -2.35187057e-02 -3.64366397e-02 -1.62088647e-02  1.65370815e-02] \n",
      "\n",
      "embed shape: (128,) \n",
      "the single token: URGENT, \n",
      "The full sentence: URGENT, IMPORTANT INFORMATION FOR O2 USER. TODAY IS YOUR LUCKY DAY! 2 FIND OUT WHY LOG ONTO HTTP://WWW.URAWINNER.COM THERE IS A FANTASTIC SURPRISE AWAITING FOR YOU\n"
     ]
    }
   ],
   "source": [
    "# Check out a single token's embeddings\n",
    "print (f\"single token embed: \\n{sample_embed[0][0]} \\n\\nembed shape: {sample_embed[0][0].shape} \\nthe single token: {random_sentence.split ()[0]} \\nThe full sentence: {random_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999202c",
   "metadata": {},
   "source": [
    "### Model 0: Getting a baseline\n",
    "as with all machine learning modelling experiments, it's important to create a baseline model so you have got a benchmark for future experiments to build upon\n",
    "\n",
    "To create our baseline model, we'll use sklearn Multinomial naive bayes using the TF-IDF formula to convert our words to numbers\n",
    "\n",
    "**NB:** ***it's common practice to use Non DL algorithm as a baseline because of their speed and then later use Dl to see if you can improve upon them***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "741113dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0 = Pipeline ([(\"tfidf\", TfidfVectorizer ()),\n",
    "                      (\"clf\", MultinomialNB ())])\n",
    "\n",
    "model_0.fit (x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fdb5e6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9623318385650225"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating our model performance\n",
    "model_0.score (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fa2e771e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score:  0.9623318385650225 \n",
      "\n",
      " Confusion_matrix: \n",
      "[[108  42]\n",
      " [  0 965]]\n"
     ]
    }
   ],
   "source": [
    "# Getting the confusion_matrix and accuracy_score\n",
    "print (f\"Accuracy_score:  {accuracy_score (y_test, y_pred)} \\n\\n Confusion_matrix: \\n{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "74f7ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9623318385650225,\n",
       " 'recall': 0.9623318385650225,\n",
       " 'Precision': 0.9639029038880305,\n",
       " 'f1_score': 0.9596669569615455}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function that evaluate our entire model results\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results (y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of binary classification model\n",
    "    \"\"\"\n",
    "    \n",
    "    model_accuracy = accuracy_score (y_true, y_pred)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support (y_true, y_pred, average = \"weighted\")\n",
    "\n",
    "    model_result = {\"accuracy\": model_accuracy,\n",
    "                    \"recall\": recall,\n",
    "                    \"Precision\": precision,\n",
    "                    \"f1_score\": f1_score}\n",
    "    return model_result\n",
    "\n",
    "calculate_results (y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c15d62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Funny fact Nobody teaches volcanoes 2 erupt, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I sent my scores to sophas and i had to do sec...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We know someone who you know that fancies you....</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only if you promise your getting out as SOON a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Congratulations ur awarded either å£500 of CD ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'll text carlos and let you know, hang on</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K.i did't see you.:)k:)where are you now?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No message..no responce..what happend?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Get down in gandhipuram and walk to cross cut ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You flippin your shit yet?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>For real tho this sucks. I can't even cook my ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Free tones Hope you enjoyed your new content. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I'm wif him now buying tix lar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Call me when u finish then i come n pick u.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dear how is chechi. Did you talk to her</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  Prediction  Actual\n",
       "0   Funny fact Nobody teaches volcanoes 2 erupt, t...           1       1\n",
       "1   I sent my scores to sophas and i had to do sec...           1       1\n",
       "2   We know someone who you know that fancies you....           1       0\n",
       "3   Only if you promise your getting out as SOON a...           1       1\n",
       "4   Congratulations ur awarded either å£500 of CD ...           0       0\n",
       "5          I'll text carlos and let you know, hang on           1       1\n",
       "6           K.i did't see you.:)k:)where are you now?           1       1\n",
       "7              No message..no responce..what happend?           1       1\n",
       "8   Get down in gandhipuram and walk to cross cut ...           1       1\n",
       "9                          You flippin your shit yet?           1       1\n",
       "10  For real tho this sucks. I can't even cook my ...           1       1\n",
       "11  Free tones Hope you enjoyed your new content. ...           0       0\n",
       "12                  I'm wif him now buying tix lar...           1       1\n",
       "13        Call me when u finish then i come n pick u.           1       1\n",
       "14            Dear how is chechi. Did you talk to her           1       1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making predictions\n",
    "y_pred = model_0.predict (x_test)\n",
    "pd.DataFrame ({\"text\": x_test[:15], \"Prediction\": y_pred[:15], \"Actual\": y_test[:15]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5172657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba0809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab663b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2039bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
